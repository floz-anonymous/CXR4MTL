# CXR4MTL

This repository contains the source code for **CXR4MTL**, a comprehensive, multi-task deep learning framework for the analysis of Chest X-ray (CXR) images. The system is built around a single, powerful `UnifiedMultiTaskModel` that can perform four interconnected tasks: lung segmentation, disease classification, radiology report generation, and visual question answering.

---

## ðŸš€ Core Features

* **Multi-Task Learning:** Capable of training and inference for four key CXR tasks from a single model architecture.
* **Unified Model Architecture:** A single `UnifiedMultiTaskModel` uses a shared `DualEncoderUNet` (fusing a U-Net and SAM-Encoder) to generate powerful, multi-scale features.
* **Task-Specific Heads:** The model utilizes specialized, high-performance heads for each task:
    * **Segmentation:** A `UNetPlusPlusDecoder`.
    * **Classification:** An `AttentionClassifierHead` using a CBAM block.
    * **Report Generation:** An `EnhancedRRGDecoder` (Transformer-based).
* **Full Diagnostic Pipeline:** Includes a `pred_full` mode that runs a complete end-to-end analysis on an image:
    1.  Runs **Segmentation** to get a lung mask and location info.
    2.  Runs **Classification** to predict the disease.
    3.  Generates an **Initial Report** conditioned on the image and class.
    4.  Creates an **Enhanced Report** by combining all findings.
    5.  Performs **VQA** by feeding the enhanced report to an LLM to answer a list of fixed questions.

---

## ðŸ”¬ The 4 Tasks Explained

### 1. Segmentation (`seg`)
* **Purpose:** To generate a precise binary mask delineating the lung fields.
* **Script:** `src/tasks/segmentation.py`
* **Model:** Uses the `UNetPlusPlusDecoder` head of the unified model.
* **Loss:** Trained using a `CombinedLoss` (a weighted sum of `DiceLoss` and `BCELoss`) to handle potential class imbalance.

### 2. Classification (`class`)
* **Purpose:** To predict a single diagnostic label for the CXR (e.g., 'Normal', 'Pneumonia', 'Tuberculosis').
* **Script:** `src/tasks/classification.py`
* **Model:** Uses the `AttentionClassifierHead` on the features from the shared encoder.
* **Loss:** Trained using standard `nn.CrossEntropyLoss`.

### 3. Report Generation (`rrg`)
* **Purpose:** To generate a concise, human-readable radiology report based on the image's visual findings.
* **Script:** `src/tasks/report_generation.py`
* **Model:** Uses the `EnhancedRRGDecoder`, a Transformer decoder that is conditioned on both the image features and the predicted class label.
* **Metrics:** Evaluated using standard NLP metrics: **BLEU**, **ROUGE**, **METEOR**, and **CIDEr**.

### 4. Answer Extraction (`vqa`)
* **Purpose:** To answer specific clinical questions about the image (e.g., "Which lung is affected?", "What is the severity?").
* **Script:** `src/tasks/answer_extraction.py` (for evaluation), `src/tasks/run_tasks.py` (for prediction).
* **Method:** This is a multi-step pipeline, not an end-to-end model.
    1.  An **enhanced report** is generated by combining findings from the Seg, Class, and RRG tasks.
    2.  This report is formatted into a prompt for a small Language Model.
    3.  Using **In-Context Learning (ICL)** from `data/example_20shot.json`, the LLM is guided to extract the answers from the report text.
    4.  The `test_vqa` mode evaluates the quality of these generated answers against a ground-truth file.

---

## ðŸ”§ Installation and Usage

### 1. Installation

1.  **Clone the repository:**
    ```bash
    git clone https://your-github-username/CXR4MTL.git
    cd CXR4MTL
    ```

2.  **Create a virtual environment (recommended):**
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    ```

3.  **Install dependencies:**
    The project uses `torch`, `transformers`, `opencv`, and `nltk`, among others.
    ```bash
    pip install -r requirements.txt
    ```
   

4.  **Download NLTK data:**
    Required for `nltk` (used in RRG metric calculations).
    ```python
    import nltk
    nltk.download('punkt')
    nltk.download('wordnet')
    ```
   

### 2. Data Setup

The framework expects data to be organized in specific folders, as defined in `src/args.py`. The default paths are:

* **Segmentation:**
    * Images: `data/segmentation/images`
    * Masks: `data/segmentation/masks`
* **Classification:**
    * Labels file: `data/classification/labels.xlsx`
    * Images: `data/classification/images`
* **Report Generation:**
    * Reports file: `data/rrg/reports.xlsx`
    * Images: `data/rrg/images`
* **VQA:**
    * Ground-truth file: `data/vqa/vqa.xlsx`
    * Few-shot examples: `data/vqa/examples_20shot.json`

### 3. How to Run

All tasks are executed via `src/main.py` using the `--mode` flag.

#### Training
* **Train Segmentation:**
    ```bash
    python src/main.py --mode train_seg \
                     --seg_image_dir data/segmentation/images \
                     --seg_mask_dir data/segmentation/masks \
                     --seg_checkpoint_path checkpoints/segmentation_best.pth \
                     --epochs 50 --batch_size 8 --lr 1e-4
    ```

* **Train Classification:**
    ```bash
    python src/main.py --mode train_class \
                     --csv_file_path_class data/classification/labels.xlsx \
                     --image_folder_path_class data/classification/images \
                     --class_checkpoint_path checkpoints/classification_best.pth \
                     --epochs 25 --batch_size 16
    ```

* **Train Report Generation:**
    ```bash
    python src/main.py --mode train_rrg \
                     --csv_file_path data/rrg/reports.xlsx \
                     --image_folder_path data/rrg/images \
                     --rrg_checkpoint_path checkpoints/rrg_best.pth \
                     --epochs 30 --batch_size 16
    ```

#### Testing
* **Test Segmentation:**
    (This will print test loss, mean IoU, and mean Dice score)
    ```bash
    python src/main.py --mode test_seg \
                     --seg_image_dir data/segmentation/images \
                     --seg_mask_dir data/segmentation/masks \
                     --seg_checkpoint_path checkpoints/segmentation_best.pth
    ```

* **Test Classification:**
    (This will print accuracy, F1, precision, recall, and save a confusion matrix)
    ```bash
    python src/main.py --mode test_class \
                     --csv_file_path_class data/classification/labels.xlsx \
                     --image_folder_path_class data/classification/images \
                     --class_checkpoint_path checkpoints/classification_best.pth
    ```

* **Test Report Generation:**
    (This will print perplexity and all text generation metrics: BLEU, ROUGE, METEOR, CIDEr)
    ```bash
    python src/main.py --mode test_rrg \
                     --csv_file_path data/rrg/reports.xlsx \
                     --image_folder_path data/rrg/images \
                     --rrg_checkpoint_path checkpoints/rrg_best.pth \
                     --csv_file_path_class data/classification/labels.xlsx
    ```

* **Test Full VQA Pipeline:**
    (This runs the entire Seg + Class + RRG + VQA-LLM pipeline and scores the final answers against your ground-truth `vqa.xlsx` file)
    ```bash
    python src/main.py --mode test_vqa \
                     --csv_file_path_vqa data/vqa/vqa.xlsx \
                     --image_folder_path data/rrg/images \
                     --csv_file_path data/rrg/reports.xlsx \
                     --seg_checkpoint_path checkpoints/segmentation_best.pth \
                     --class_checkpoint_path checkpoints/classification_best.pth \
                     --rrg_checkpoint_path checkpoints/rrg_best.pth \
                     --examples_path data/vqa/examples_20shot.json
    ```

#### Prediction (on a single image)
* **Predict Segmentation:**
    (Saves a `_segmentation.png` mask in the same directory)
    ```bash
    python src/main.py --mode pred_seg \
                     --seg_checkpoint_path checkpoints/segmentation_best.pth \
                     --image_to_predict_path sample.jpg
    ```

* **Predict Classification:**
    (Prints the predicted class and confidence)
    ```bash
    python src/main.py --mode pred_class \
                     --class_checkpoint_path checkpoints/classification_best.pth \
                     --csv_file_path_class data/classification/labels.xlsx \
                     --image_to_predict_path sample.jpg
    ```

* **Predict Report Generation:**
    (Prints the generated report. Requires a classification model to get the class label first)
    ```bash
    python src/main.py --mode pred_rrg \
                     --rrg_checkpoint_path checkpoints/rrg_best.pth \
                     --class_checkpoint_path checkpoints/classification_best.pth \
                     --csv_file_path data/rrg/reports.xlsx \
                     --csv_file_path_class data/classification/labels.xlsx \
                     --image_to_predict_path sample.jpg
    ```
